{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# เรียกใช้ library สำหรับทำงานประกอบด้วย numpy pandas seaborn เเละ matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024186</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.024186</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Ever_Married       Age  Graduated  Profession  Work_Experience  \\\n",
       "0  0.015047      0.000000  0.005260   0.000000    0.003284         0.002718   \n",
       "1  0.000000      0.014676  0.009085   0.014188    0.009852         0.002718   \n",
       "2  0.000000      0.014676  0.016018   0.014188    0.009852         0.002718   \n",
       "3  0.015047      0.014676  0.016018   0.014188    0.016421         0.000000   \n",
       "4  0.000000      0.014676  0.009563   0.014188    0.006568         0.002718   \n",
       "\n",
       "   Spending_Score  Family_Size     Var_1 Segmentation  \n",
       "0        0.000000     0.012819  0.007649            D  \n",
       "1        0.012093     0.009614  0.007649            A  \n",
       "2        0.000000     0.003205  0.012749            B  \n",
       "3        0.024186     0.006410  0.012749            B  \n",
       "4        0.024186     0.019229  0.012749            A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# อ่านข้อมูลไฟล์ csv จาก https://raw.githubusercontent.com/nawinpoyen7/MachineLearning/main/DataSet/DataChange.csv\n",
    "# และเเสดง 5 ตัวอย่างเเรก เพื่อตรวจสอบข้อมูล\n",
    "url='https://raw.githubusercontent.com/nawinpoyen7/MachineLearning/main/DataSet/CombDataSet.csv'\n",
    "dataset=pd.read_csv(url)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    2268\n",
       "A    1972\n",
       "C    1970\n",
       "B    1858\n",
       "Name: Segmentation, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Segmentation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
       "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
       "       'Segmentation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vals=['Gender','Ever_Married','Age','Graduated','Profession','Work_Experience','Spending_Score','Family_Size','Var_1']\n",
    "#sns.pairplot(data=dataset,hue='Segmentation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # ปรับช่วงข้อมูลด้วยวิธี standardization\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " # กำหนดตัวเเปร X เพื่อเก็บข้อมูลดอกไอริสสำหรับ features ที่ต้องการ \n",
    "Vals=['Profession', 'Spending_Score', 'Age', 'Graduated']\n",
    "X=dataset[Vals] \n",
    "# สร้าง object ชื่อ scaler จาก class ของ StandardScaler เพื่อใช้สำหรับการเรียกใช้ในการปรับช่วงข้อมูล\n",
    "scaler = StandardScaler()  \n",
    "# ปรับช่วงข้อมูลเเละเก็บอยู่ในตัวเเปร X_scale ซึ่งข้อมูลจะอยู่ในรูปของ numpy array\n",
    "X_scale=scaler.fit_transform(X)  \n",
    "# ปรับให้เเสดงด้วยตัวเลขทศนิยม 4 ตำเเหน่ง \n",
    "X_scale = X_scale.round(4) \n",
    "y = np.array(dataset['Segmentation'])\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_targets = encoder.fit_transform(dataset[['Segmentation']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size=0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_targets, \n",
    "    test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# สร้าง hidden layer ที่ 1 ประกอบด้วย 1000 โหนด ซึ่งเชื่อมต่อกับ Input layer ประกอบด้วย 4 โหนด \n",
    "# เเละเลือกใช้ ReLu เป็น activation function \n",
    "model.add(Dense(1000, input_dim=4, activation='relu'))\n",
    "\n",
    "# สร้าง hidden layer ที่ 2 ประกอบด้วย 1000 โหนด ซึ่งเชื่อมต่อกับ hidden layer ที่ 1 ประกอบด้วย 1000 โหนด \n",
    "# เเละเลือกใช้ ReLu เป็น activation function \n",
    "model.add(Dense(1000, input_dim=1000, activation='relu'))\n",
    "\n",
    "# สร้าง hidden layer ที่ 3 ประกอบด้วย 1000 โหนด ซึ่งเชื่อมต่อกับ hidden layer ที่ 2 ประกอบด้วย 1000 โหนด \n",
    "# เเละเลือกใช้ ReLu เป็น activation function\n",
    "model.add(Dense(1000, input_dim=1000, activation='relu'))\n",
    "\n",
    "# สร้าง hidden layer ที่ 4 ประกอบด้วย 1000โหนด ซึ่งเชื่อมต่อกับ hidden layer ที่ 3 ประกอบด้วย 1000 โหนด \n",
    "# เเละเลือกใช้ ReLu เป็น activation function\n",
    "model.add(Dense(1000, input_dim=1000, activation='relu'))\n",
    "\n",
    "# สร้าง output layer ประกอบด้วย 4 โหนด ซึ่งเชื่อมต่อกับ hidden layer ที่ 4 ประกอบด้วย 1000 โหนด \n",
    "# เเละเลือกใช้ sigmoid เป็น activation function \n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# กำหนดให้ optimizer ใช้ method adam ในการปรับปรุงค่าด้วย learning rate = 0.005\n",
    "# from keras.optimizers import Adam\n",
    "# optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anwa\\Downloads\\machine\\Newfolder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "5647/5647 [==============================] - 52s 9ms/step - loss: 0.1884 - accuracy: 0.2908\n",
      "Epoch 2/100\n",
      "5647/5647 [==============================] - 53s 9ms/step - loss: 0.1694 - accuracy: 0.4202\n",
      "Epoch 3/100\n",
      "5647/5647 [==============================] - 55s 10ms/step - loss: 0.1680 - accuracy: 0.4358\n",
      "Epoch 4/100\n",
      "5647/5647 [==============================] - 53s 9ms/step - loss: 0.1653 - accuracy: 0.4401\n",
      "Epoch 5/100\n",
      "5647/5647 [==============================] - 53s 9ms/step - loss: 0.1651 - accuracy: 0.4417\n",
      "Epoch 6/100\n",
      "5647/5647 [==============================] - 55s 10ms/step - loss: 0.1657 - accuracy: 0.4526\n",
      "Epoch 7/100\n",
      "5647/5647 [==============================] - 55s 10ms/step - loss: 0.1629 - accuracy: 0.4493\n",
      "Epoch 8/100\n",
      "5647/5647 [==============================] - 53s 9ms/step - loss: 0.1635 - accuracy: 0.4576\n",
      "Epoch 9/100\n",
      "5647/5647 [==============================] - 66s 12ms/step - loss: 0.1622 - accuracy: 0.4532\n",
      "Epoch 10/100\n",
      "5647/5647 [==============================] - 67s 12ms/step - loss: 0.1622 - accuracy: 0.4555\n",
      "Epoch 11/100\n",
      "5647/5647 [==============================] - 60s 11ms/step - loss: 0.1604 - accuracy: 0.4680\n",
      "Epoch 12/100\n",
      "5647/5647 [==============================] - 57s 10ms/step - loss: 0.1607 - accuracy: 0.4606\n",
      "Epoch 13/100\n",
      "5647/5647 [==============================] - 61s 11ms/step - loss: 0.1600 - accuracy: 0.4613\n",
      "Epoch 14/100\n",
      "5647/5647 [==============================] - 55s 10ms/step - loss: 0.1597 - accuracy: 0.4640\n",
      "Epoch 15/100\n",
      "5647/5647 [==============================] - 54s 10ms/step - loss: 0.1580 - accuracy: 0.4728\n",
      "Epoch 16/100\n",
      "5647/5647 [==============================] - 53s 9ms/step - loss: 0.1585 - accuracy: 0.4673\n",
      "Epoch 17/100\n",
      "5647/5647 [==============================] - 54s 10ms/step - loss: 0.1576 - accuracy: 0.4778\n",
      "Epoch 18/100\n",
      "5647/5647 [==============================] - 56s 10ms/step - loss: 0.1574 - accuracy: 0.4792\n",
      "Epoch 19/100\n",
      "5647/5647 [==============================] - 53s 9ms/step - loss: 0.1574 - accuracy: 0.4838\n",
      "Epoch 20/100\n",
      "5647/5647 [==============================] - 56s 10ms/step - loss: 0.1564 - accuracy: 0.4815\n",
      "Epoch 21/100\n",
      "5647/5647 [==============================] - 58s 10ms/step - loss: 0.1556 - accuracy: 0.4857\n",
      "Epoch 22/100\n",
      "5647/5647 [==============================] - 60s 11ms/step - loss: 0.1556 - accuracy: 0.4905\n",
      "Epoch 23/100\n",
      "5647/5647 [==============================] - 55s 10ms/step - loss: 0.1551 - accuracy: 0.4842\n",
      "Epoch 24/100\n",
      "5647/5647 [==============================] - 67s 12ms/step - loss: 0.1553 - accuracy: 0.4847\n",
      "Epoch 25/100\n",
      "5647/5647 [==============================] - 60s 11ms/step - loss: 0.1549 - accuracy: 0.4811\n",
      "Epoch 26/100\n",
      "5647/5647 [==============================] - 61s 11ms/step - loss: 0.1547 - accuracy: 0.4870\n",
      "Epoch 27/100\n",
      "5647/5647 [==============================] - 52s 9ms/step - loss: 0.1545 - accuracy: 0.4870\n",
      "Epoch 28/100\n",
      "2016/5647 [=========>....................] - ETA: 36s - loss: 0.1529 - accuracy: 0.5074"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9f69fece4b42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\machine\\Newfolder\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Downloads\\machine\\Newfolder\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Downloads\\machine\\Newfolder\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
